{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we defined our own exposure estimation modell. Based on the input picture it predicts an amplification ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameters which can easily be changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 512\n",
    "WIDTH = 512\n",
    "BATCHSIZE = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Embedding\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "import os\n",
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "import rawpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ratio function with the appropiate exposure ratio. We use this as the groud truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Ratio(in_path, truth_path):\n",
    "    in_exposure = float(in_path[53:-5])\n",
    "    gt_exposure = float(truth_path[52:-5])\n",
    "    ratio = min(gt_exposure / in_exposure, 300)\n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the model, we use a cnn with 3 conv. layers,dropout, and a flatten layer before the last dense with 1 output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 255, 255, 10)      280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_18 (MaxPooling (None, 127, 127, 10)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 62, 62, 10)        2510      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_19 (MaxPooling (None, 31, 31, 10)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 31, 31, 10)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 14, 14, 10)        2510      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_20 (MaxPooling (None, 7, 7, 10)          0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 490)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 491       \n",
      "=================================================================\n",
      "Total params: 5,791\n",
      "Trainable params: 5,791\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Conv2D(10, kernel_size=(3, 3), activation='relu', input_shape=(HEIGHT, WIDTH, 3), strides= 2)) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Conv2D(10, (5, 5), activation='relu', strides = 2)) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(10, (5, 5), activation='relu', strides = 2)) \n",
    "model.add(MaxPooling2D(pool_size=(2, 2))) \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1))\n",
    "\n",
    "#loss is mean squared error, optimizer is adam\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()\n",
    "\n",
    "Model = model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "load in the train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/takats_balint1/deephf/data/Sony/short/00001_00_0.1s.ARW', '/home/takats_balint1/deephf/data/Sony/long/00001_00_10s.ARW']\n"
     ]
    }
   ],
   "source": [
    "trainPath = \"/home/takats_balint1/deephf/data/Sony_train_list.txt\"\n",
    "replaceString = \"/home/takats_balint1/deephf/data\"\n",
    "\n",
    "trainData = []\n",
    "with open(trainPath) as File:\n",
    "    for line in File:\n",
    "        data, truth, _, _ = line.split()\n",
    "        data = data.replace(\".\", replaceString, 1)\n",
    "        truth = truth.replace(\".\", replaceString, 1)\n",
    "        # This method is slow but we only have a 1000 lines so this quick and dirty algortihm will do just fine\n",
    "        trainData.append([data, truth])\n",
    "print (trainData[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "training the model: after reading the raw image in we resize it to match the input_size of the network.\n",
    "Truth will be the reference/output for the network which we supposed to get after a succesful training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATA LOADED\n",
      "DATA LOADED\n",
      "DATA LOADED\n",
      "DATA LOADED\n",
      "DATA LOADED\n",
      "DATA LOADED\n",
      "DATA LOADED\n",
      "DATA LOADED\n"
     ]
    }
   ],
   "source": [
    "#Model = network()\n",
    "\n",
    "trainPermutation = np.random.permutation(len(trainData[:16]))\n",
    "data = [None]*BATCHSIZE\n",
    "truth = [None]*BATCHSIZE\n",
    "for i in range(0, len(trainPermutation), BATCHSIZE):\n",
    "    for j in range(BATCHSIZE):\n",
    "        \n",
    "        ratio = Ratio(trainData[trainPermutation[i]][0], trainData[trainPermutation[i]][1])\n",
    "        truth[j] = [ratio]\n",
    "        raw = rawpy.imread(trainData[trainPermutation[i]][0])\n",
    "        raw = raw.postprocess(use_camera_wb=True, half_size=False, no_auto_bright=True, output_bps=16)\n",
    "        raw = np.float32(raw / 65535.0)\n",
    "        raw = cv2.resize(raw, dsize=(HEIGHT, WIDTH), interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "        data[j] = raw\n",
    "\n",
    "    print(\"DATA LOADED\")\n",
    "    Model.train_on_batch(np.array(data), np.array(truth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
